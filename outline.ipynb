{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alex Malz, David Mykytyn\n",
    "\n",
    "This is a sandbox for developing an unsupervised classifier of astronomical lightcurves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "import scipy.optimize as spo\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LC = namedtuple('LC', ('x', 'y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " may need to preprocess to keep it reasonable, constraints on delta/stretch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate some mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gauss(scale, loc=0., amp=1., const=0.):\n",
    "    func = sps.norm(loc, scale)\n",
    "    out = lambda x: amp * func.pdf(x) + const\n",
    "    return out\n",
    "\n",
    "def make_sine(period, phase=0., amp=1., const=0.):\n",
    "    func = lambda x: amp * (np.sin(period * x + phase)) + const\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cadence(x, scatter):\n",
    "    assert(np.all((x[1:]-x[:-1]) > scatter))\n",
    "    jitter = (np.random.uniform(np.shape(x)) - 0.5) * scatter * 2.\n",
    "    perturbed = x + jitter\n",
    "    return perturbed\n",
    "\n",
    "def noisify_obs(y, scatter):\n",
    "    errs = scatter * np.ones_like(y)\n",
    "    new_y = y + sps.norm(0., scatter).rvs(np.shape(y))\n",
    "    return(new_y, errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_cadence = np.arange(0., 200., 5.)\n",
    "\n",
    "gmodel = make_gauss(10., 100., 50., 1.)\n",
    "gtimes = make_cadence(def_cadence, 0.5)\n",
    "gphot, gerr = noisify_obs(gmodel(gtimes), 0.1)\n",
    "glc = LC(gtimes, gphot)\n",
    "\n",
    "smodel = make_sine(20., 0., 5., 5.)\n",
    "stimes = make_cadence(def_cadence, 0.5)\n",
    "sphot, serr = noisify_obs(smodel(stimes), 0.3)\n",
    "slc = LC(stimes, sphot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(glc.x, glc.y, yerr=gerr, linestyle='None', marker='o')\n",
    "plt.errorbar(slc.x, slc.y, yerr=serr, linestyle='None', marker='+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permitted transformations\n",
    "\n",
    "* shiftx\n",
    "* stretchx\n",
    "* shifty\n",
    "* stretchy\n",
    "* (cross-talk between bands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(lc, deltax, deltay, stretchx, stretchy):\n",
    "    new_x = (stretchx * lc.x) + deltax\n",
    "    new_y = (stretchy * lc.y) + deltay\n",
    "    return LC(new_x, new_y)\n",
    "\n",
    "def merge(lca, lcb):\n",
    "#     minx, maxx = max(min(lca.x), min(lcb.x)), min(max(lca.x), max(lcb.x))\n",
    "    new_x = np.concatenate((lca.x, lcb.x))\n",
    "    new_y = np.concatenate((lca.y, lcb.y))\n",
    "    order = np.argsort(new_x)\n",
    "    ord_x = new_x[order]\n",
    "    ord_y = new_y[order]\n",
    "#     condition = np.where(np.logical_and(ord_x <= maxx, ord_x >= minx))\n",
    "#     ord_x = ord_x[condition]\n",
    "#     ord_y = ord_y[condition]\n",
    "    return LC(ord_x, ord_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce to summary statistics (consistency metric)\n",
    "\n",
    "Contenders:\n",
    "\n",
    "* periodogram -- identify periodicity and stochastic noise levels\n",
    "* flux per time bins -- trends keeping bin size constant but changing bin ends\n",
    "* abs/percent change in color and total flux/magnitude\n",
    "\n",
    "find MAP/MLE of p(A = B | lc_A, lc_B)\n",
    "optimize over shift/stretch params\n",
    "\n",
    "merge (x_A, x_B) and (y_A, y_B)\n",
    "\n",
    "Regularization is going to be really hard!\n",
    "\n",
    "connect the dots is taking an arc length\n",
    "\n",
    "could use the gaussian error bars to get probability that new hypothesis point lies on original line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_the_dots(lc):\n",
    "#     n_points = len(lc.x)\n",
    "    x_difs = (lc.x[1:] - lc.x[:-1])\n",
    "    y_difs = lc.y[1:] - lc.y[:-1]\n",
    "    sol = np.sqrt(x_difs ** 2 + y_difs ** 2)\n",
    "    return np.sum(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gtimes2 = gtimes + 50. * np.ones_like(gtimes)#ake_cadence(def_cadence, 0.5)\n",
    "gphot2, gerr2 = gphot, gerr#noisify_obs(gmodel(gtimes2), 0.1)\n",
    "glc2 = LC(gtimes2, gphot2)\n",
    "# glc2 = transform(glc, 5., 0., 1., 1.)\n",
    "plt.plot(glc.x, glc.y, label='original')\n",
    "plt.plot(glc2.x, glc2.y, label='shifted')\n",
    "plt.plot(merge(glc, glc2).x, merge(glc, glc2).y, label='merged')\n",
    "plt.legend()\n",
    "print((connect_the_dots(glc), connect_the_dots(glc2), connect_the_dots(merge(glc, glc2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((connect_the_dots(glc), connect_the_dots(glc2), connect_the_dots(merge(glc, transform(glc2, -0.5, 0., 1., 1.)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_prob(lca, lcb, ivals=(0., 0., 1., 1.)):\n",
    "    \n",
    "    origa = connect_the_dots(lca)\n",
    "#     origb = connect_the_dots(lcb)\n",
    "    xdifmax = np.max((lca.x[-1]-lca.x[0], lcb.x[-1]-lcb.x[0]))\n",
    "    xdifmin = np.min((np.min(lca.x[1:]-lca.x[:-1]), np.min(lcb.x[-1]-lcb.x[0])))\n",
    "    ydifmax = np.max((np.max(lca.y)-np.min(lca.y), np.max(lcb.y)-np.min(lcb.y)))\n",
    "    ydifmin = np.min((np.min(lca.y[1:]-lca.y[:-1]), np.min(lcb.y[-1]-lcb.y[0])))\n",
    "\n",
    "    def dxlim_hi(params):\n",
    "        return xdifmax - params[0]\n",
    "    def dxlim_lo(params):\n",
    "        return params[0] - xdifmin\n",
    "    def dylim_hi(params):\n",
    "        return ydifmax - params[1]\n",
    "    def dylim_lo(params):\n",
    "        return params[1] - ydifmin\n",
    "    def sxlim_hi(params):\n",
    "        return xdifmax - params[2] * xdifmin\n",
    "    def sxlim_lo(params):\n",
    "        return params[2] * xdifmax - xdifmin\n",
    "    def sylim_hi(params):\n",
    "        return ydifmax - params[3] * ydifmin\n",
    "    def sylim_lo(params):\n",
    "        return params[3] * ydifmax - ydifmin\n",
    "    def slim(params):\n",
    "        return params[2:]\n",
    "\n",
    "    constraints = [dxlim_hi, dylim_hi, dylim_lo, sxlim_hi, sxlim_lo, sylim_hi, sylim_lo, slim]\n",
    "    \n",
    "    debug = []\n",
    "    def _helper(params):\n",
    "        (deltax, deltay, stretchx, stretchy) = params\n",
    "        lc = transform(lcb, deltax, deltay, stretchx, stretchy)\n",
    "        new_len = connect_the_dots(lc)\n",
    "        lc_both = merge(lca, lc) \n",
    "        length = connect_the_dots(lc_both)\n",
    "        to_min = length - origa\n",
    "        return(to_min)\n",
    "    \n",
    "    res = spo.fmin_cobyla(_helper, ivals, constraints)\n",
    "    \n",
    "    tmp = transform(lcb, res[0], res[1], res[2], res[3])\n",
    "    fin = merge(lca, tmp)\n",
    "    debug = connect_the_dots(fin)\n",
    "    return(res, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans, debug = find_max_prob(glc, glc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (dx, dy, sx, sy) = ans\n",
    "# print(ans)\n",
    "# fin = transform(glc2, dx, dy, sx, sy)\n",
    "# print(connect_the_dots(fin))\n",
    "# plt.plot(glc.x, glc.y)\n",
    "# plt.plot(fin.x, fin.y)\n",
    "# plt.plot(merge(glc, fin).x, merge(glc, fin).y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstruct(lca, lcb, params, truea='', trueb=''):\n",
    "    (dx, dy, sx, sy) = params\n",
    "#     print(params)\n",
    "    fin = transform(lcb, dx, dy, sx, sy)\n",
    "    print(fin.x)\n",
    "    plt.plot(lca.x, lca.y, label='reference'+truea)\n",
    "    plt.plot(lcb.x, lcb.y, label='hypothetical'+trueb)\n",
    "    plt.plot(fin.x, fin.y, label='transformed'+trueb)\n",
    "    plt.plot(merge(lca, fin).x, merge(lca, fin).y, label='merged')\n",
    "    plt.title(str(params))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruct(glc, glc2, ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do this many times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_obj = 10\n",
    "cls_models = [make_gauss, make_sine]\n",
    "cls_params = [{'scale': 10., 'loc': 100., 'amp': 50., 'const': 1.}, \n",
    "              {'period': 20., 'phase': 0., 'amp': 5., 'const': 5.}]\n",
    "cls_wts = None # even split for now\n",
    "num_cls = len(cls_models)\n",
    "# will need a way to draw model params\n",
    "\n",
    "def_cadence = np.arange(0., 200., 5.)\n",
    "lcs = []\n",
    "truth = np.random.choice(range(num_cls), num_obj, p=cls_wts)\n",
    "ids, inds, cts = np.unique(truth, return_counts=True, return_inverse=True)\n",
    "# print(ids, cts, inds)\n",
    "\n",
    "for i in range(num_obj):\n",
    "    times = make_cadence(def_cadence, 0.5)\n",
    "    model = cls_models[ids[inds[i]]](**cls_params[ids[inds[i]]])\n",
    "    phot, err = noisify_obs(model(times), 0.1)\n",
    "    lcs.append(LC(times, phot))\n",
    "    \n",
    "masks = np.zeros((num_cls, num_obj, num_obj))\n",
    "for i in ids:\n",
    "    which_ones = np.where(truth == i)[0]\n",
    "#     print(which_ones)\n",
    "    pairs = np.array(list(itertools.permutations(which_ones, 2))).T\n",
    "#     print(pairs)\n",
    "    masks[i, pairs[0], pairs[1]] += 1\n",
    "    \n",
    "# print(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_pipeline(all_lcs):\n",
    "    how_many = len(all_lcs)\n",
    "    indices = range(how_many)\n",
    "    dump_difs = np.empty((how_many, how_many))\n",
    "    dump_params = []\n",
    "    \n",
    "    for i in indices:\n",
    "        one_set = []\n",
    "        for j in indices:\n",
    "            ans, fin_len = find_max_prob(all_lcs[i], all_lcs[j])\n",
    "#             print(ans, fin_len)\n",
    "            one_set.append(np.asarray(ans))\n",
    "            dump_difs[i][j] = fin_len\n",
    "        dump_params.append(one_set)\n",
    "    dump_params = np.array(dump_params)\n",
    "            \n",
    "    return(dump_params, dump_difs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params, all_difs = mini_pipeline(lcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for symmetry -- really thought these would be symmetric. . .\n",
    "plt.matshow(np.sum(masks, axis=0))\n",
    "layered = np.swapaxes(all_params, 0, -1)\n",
    "\n",
    "deltafunc = lambda x: np.abs(x)\n",
    "stretchfunc = lambda x: np.min(np.array([x, 1./x]).T, axis=-1)\n",
    "funcs = [deltafunc, deltafunc, stretchfunc, stretchfunc]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.matshow(funcs[i](layered[i]))\n",
    "    plt.plot([0, num_obj-1], [0, num_obj-1], color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster in the space of summary statistics\n",
    "\n",
    "kdtree (and more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mask = np.zeros((num_obj, num_obj))\n",
    "# for i in range(4):\n",
    "#     global_mask = np.logical_or(global_mask, masks[i])\n",
    "for i in range(num_cls):\n",
    "    global_mask = np.logical_or(global_mask, masks[i])\n",
    "    plt.hist((all_difs * masks[i]).flatten(), alpha=0.25, label=str(i))\n",
    "plt.hist(all_difs[~global_mask[i]].flatten(), alpha=0.25, label='no match')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(all_params.reshape(100, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listerize(data, masks):\n",
    "    datashape = np.shape(data)\n",
    "    global_mask = np.ma.make_mask_none(np.shape(masks)[1:])\n",
    "    layers = []\n",
    "    for i in range(len(masks)):# per class\n",
    "        one_mask = np.ma.make_mask(masks[i])\n",
    "        layer = np.ma.array(data, mask=np.ma.logical_not(one_mask)[np.newaxis])#data * masks[i][np.newaxis]\n",
    "        global_mask = np.ma.mask_or(global_mask, one_mask)\n",
    "        layers.append(layer.compressed())\n",
    "        \n",
    "    global_mask = np.ma.make_mask(global_mask)\n",
    "    others = np.ma.array(data, mask=global_mask[np.newaxis]).compressed()#data * ~global_mask[np.newaxis]\n",
    "    return(layers, others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class, mismatch = listerize(all_difs, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_estimation(m1, m2):\n",
    "    X, Y = np.mgrid[min(m1):max(m1):100j, min(m2):max(m2):100j]                                                     \n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])                                                       \n",
    "    values = np.vstack([m1, m2])                                                                        \n",
    "    kernel = sps.gaussian_kde(values)                                                             \n",
    "    Z = np.reshape(kernel(positions).T, X.shape)\n",
    "    return X, Y, Z\n",
    "\n",
    "def mycorner(data, keys, colors, maps, lims=None, pre_densities=None, filename='plot.pdf'):\n",
    "    ncol = len(keys)\n",
    "    fig = plt.figure(figsize=(ncol*5, ncol*5))\n",
    "    ax = [[fig.add_subplot(ncol, ncol, ncol * i + j + 1) for j in range(i+1)] for i in range(ncol)]\n",
    "#     print(len(data), len(colors))\n",
    "    for k in range(len(data)):\n",
    "        datum = data[k]\n",
    "        npoints = len(datum)\n",
    "        for i in range(ncol):\n",
    "            for j in range(i+1):\n",
    "                if i == j:\n",
    "#                     print(datum[keys[i]])\n",
    "                    ax[i][j].hist(datum[i].data, histtype='step', linewidth=2, alpha=0.5, color=colors[k])\n",
    "                    ax[i][j].set_xlabel(keys[i])\n",
    "                else:\n",
    "#                     if (npoints >= 1e4 or npoints <= 100):\n",
    "                    ax[i][j].scatter(datum[i].data, datum[j].data, color=colors[k], alpha=0.5)\n",
    "#                     else:\n",
    "#                         if pre_densities is None:\n",
    "#                             x, y, z = density_estimation(datum[keys[i]], datum[keys[j]])\n",
    "#                         else:\n",
    "#                             (x, y, z) = pre_densities[i][j]\n",
    "#                         ax[i][j].contour(x, y, z, cmap=plt.get_cmap(maps[k]) , alpha=0.5)\n",
    "                    ax[i][j].set_xlabel(keys[i])\n",
    "                    ax[i][j].set_ylabel(keys[j])\n",
    "#                     if lims is not None:\n",
    "#                         ax[i][j].set_xlim(lims)\n",
    "#                         ax[i][j].set_ylim(lims)\n",
    "#     fig.savefig(filename, dpi=100)\n",
    "    return#(fig)\n",
    "# replace with 2d histogram for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycorner([per_class[0], per_class[1], mismatch], ['deltax', 'deltay', 'stretchx', 'stretchy'], ['r', 'g', 'b'], ['Reds', 'Greens', 'Blues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_obj):\n",
    "    for j in range(num_obj):\n",
    "        plot_reconstruct(lcs[i], lcs[j], all_params[i][j], truea=str(truth[i]), trueb=str(truth[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other ideas\n",
    "\n",
    "pairwise combinations/comparisons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
